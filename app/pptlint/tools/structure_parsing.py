"""
åŸºäº parser.py è§£æç»“æœçš„é«˜å±‚ä¿¡æ¯æŠ½å–å·¥å…·

åŠŸèƒ½ï¼š
- ä» parsing_result.jsonï¼ˆæˆ–ä¼ å…¥çš„ç»“æ„åŒ–æ•°æ®ï¼‰ä¸­æå–ï¼š
  1) æ¯é¡µæ ‡é¢˜ï¼ˆä¼˜å…ˆä½¿ç”¨"æ˜¯å¦æ˜¯æ ‡é¢˜å ä½ç¬¦"ä¸º True çš„æ–‡æœ¬å—ï¼‰
  2) ç« èŠ‚åä¸ç›®å½•é¡µè¯†åˆ«ï¼ˆç»“åˆå¤§æ¨¡å‹ï¼‰
  3) å…¨å±€ä¸»é¢˜/ä¸»é¢˜è¯ï¼ˆç»“åˆå¤§æ¨¡å‹ï¼‰

è¯´æ˜ï¼š
- æ‰€æœ‰å‡½æ•°ä»…ä¾èµ– parser çš„è¾“å‡ºç»“æ„ï¼Œä¸ä¿®æ”¹ parser è¡Œä¸º
- éœ€è¦è°ƒç”¨å¤§æ¨¡å‹æ—¶ï¼Œå¤ç”¨ç°æœ‰ llm.py/llm_review.py çš„æ¨¡å‹è°ƒç”¨èƒ½åŠ›
"""

from typing import List, Dict, Any, Optional
import json
import os
import sys


# å…¼å®¹è„šæœ¬ç›´è·‘ï¼šå°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.path åå†å¯¼å…¥
_CURR = os.path.dirname(os.path.abspath(__file__))
_ROOT = os.path.abspath(os.path.join(_CURR, os.pardir, os.pardir))
if _ROOT not in sys.path:
    sys.path.insert(0, _ROOT)
from pptlint.llm import LLMClient


def load_parsing_result(path: str = "parsing_result.json") -> List[Dict[str, Any]]:
    """åŠ è½½ parser è¾“å‡ºçš„ JSON ç»“æœã€‚
    è¿”å› slides_data: List[Dict[str, Any]]
    """
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def infer_all_structures(slides_data: List[Dict[str, Any]], llm: Optional[LLMClient] = None) -> Dict[str, Any]:
    """ä¸€æ¬¡æ€§å‘å¤§æ¨¡å‹è¯¢é—®å¹¶è¿”å›ï¼šé¢˜ç›®ã€ç›®å½•é¡µã€ç« èŠ‚åˆ’åˆ†ã€æ¯é¡µæ ‡é¢˜ã€‚
    è¿”å›ï¼š{"topic": str, "contents": [int], "sections": [{"title": str, "pages": [int]}], "titles": [str]}
    """
    print(f"ğŸ” å¼€å§‹åˆ†æPPTç»“æ„ï¼Œå¹»ç¯ç‰‡æ•°é‡: {len(slides_data)}")
    
    # ç›´æ¥ä¼ é€’PPTåŸå§‹æ•°æ®ç»™å¤§æ¨¡å‹åˆ†æ
    prompt = f"""ä½ æ˜¯PPTç»“æ„åˆ†æä¸“å®¶ã€‚ä»»åŠ¡ï¼šåŸºäºæä¾›çš„PPTåŸå§‹æ•°æ®è¿›è¡Œåˆ†æï¼Œåˆ†æå‡ºPPTçš„é¢˜ç›®ã€ç›®å½•ã€ç« èŠ‚é¡µã€æ¯é¡µæ ‡é¢˜ï¼Œå¹¶åªè¾“å‡ºåˆæ³•JSONã€‚

        å®šä¹‰ï¼š
        - é¢˜ç›®(topic)ï¼šPPTçš„åç§°ï¼Œä¸€èˆ¬åœ¨é¦–é¡µçš„æ ‡é¢˜å ä½ç¬¦ä¸­ã€‚
        - ç›®å½•(contents)ï¼šåˆ—å‡ºå…¨å·ä¸»è¦ç« èŠ‚æˆ–å†…å®¹æçº²çš„é¡µé¢ï¼›å¸¸å«'ç›®å½•'ã€'CONTENTS'ç­‰ã€‚éœ€è¦è¿”å›å…·ä½“çš„ç›®å½•å†…å®¹ï¼Œæ ¼å¼ä¸º[{{"page": int, "title": str, "level": int}}]ï¼Œå…¶ä¸­levelè¡¨ç¤ºå±‚çº§ï¼ˆ1ä¸ºä¸€çº§æ ‡é¢˜ï¼Œ2ä¸ºäºŒçº§æ ‡é¢˜ç­‰ï¼‰ã€‚
        - ç« èŠ‚é¡µ(sections)ï¼š**é‡è¦**ï¼šç« èŠ‚é¡µæ˜¯æŒ‡PPTä¸­çœŸå®å­˜åœ¨çš„ç« èŠ‚åˆ†éš”é¡µé¢ï¼Œä¸æ˜¯æ€»ç»“å‡ºæ¥çš„ã€‚ç« èŠ‚é¡µçš„ç‰¹å¾ï¼š
            * é¦–ä¸ªç« èŠ‚é¡µä¸€èˆ¬å‡ºç°åœ¨ç›®å½•é¡µä¹‹åï¼Œä¹Ÿå¯èƒ½æ²¡æœ‰ç« èŠ‚é¡µ
            * ç« èŠ‚é¡µçš„å†…å®¹é€šå¸¸æ˜¯ç›®å½•ä¸­çš„ä¸€ä¸ªæ¡ç›®ï¼ˆæ ‡é¢˜æˆ–æ ‡é¢˜+åºå·ï¼‰ï¼Œä½†ä¸€å®šè¦æ³¨æ„è¿™åªæ˜¯é€šå¸¸æƒ…å†µï¼Œæœ‰å¯èƒ½äººä¸ºä¹¦å†™é”™è¯¯ï¼Œå®é™…å†…å®¹å¯èƒ½ä¸ç›®å½•ä¸ä¸€è‡´ï¼Œéœ€è¦æ ¹æ®çœŸå®çš„çš„ç« èŠ‚é¡µå†…å®¹è¾“å‡ºï¼Œå³ä½¿äººä¸ºé”™è¯¯é¡µä¸è¦ä¿®æ­£
            * ç« èŠ‚é¡µé€šå¸¸åªæœ‰ä¸€ä¸ªæ–‡æœ¬å—ï¼Œ å¹¶ä¸”æ–‡æœ¬å—åœ¨é¡µé¢ä¸­é—´ï¼Œå†…å®¹æ˜¯ç« èŠ‚åæˆ–ç« èŠ‚å+åºå·
            * å¦‚æœè¯¥é¡µçš„å†…å®¹æ¯”è¾ƒå¤šï¼Œä¸€èˆ¬è‚¯å®šä¸æ˜¯ç« èŠ‚é¡µ
            * å¦‚æœPPTä¸­æ²¡æœ‰æ˜æ˜¾çš„ç« èŠ‚åˆ†éš”é¡µï¼Œåˆ™sectionsä¸ºç©ºæ•°ç»„
            * æ ¼å¼ï¼šsections[i].titleä¸ºç« èŠ‚é¡µçš„æ ‡é¢˜ï¼Œsections[i].pagesä¸ºè¯¥ç« èŠ‚é¡µçš„é¡µç ï¼ˆé€šå¸¸åªæœ‰ä¸€é¡µï¼‰
        - æ¯é¡µæ ‡é¢˜(titles)ï¼šç¬¬ i+1 é¡µçš„ä¸»æ ‡é¢˜ï¼Œ ä¸€èˆ¬ä½äºæ¯é¡µçš„å·¦ä¸Šè§’ï¼Œ å¦‚æœè¯¥é¡µæ²¡æœ‰æ ‡é¢˜ï¼Œåˆ™titles[i]ä¸ºç©ºã€‚

        è¯·åˆ†æçš„è¦ç‚¹ï¼š
        - **ä¸è¦è·¨è¶Šä¿¡æ¯è¾¹ç•Œ**ï¼š æ¯é¡µè¾“å‡ºçš„ç»“æœåªèƒ½åŒ…å«è¯¥é¡µçš„ä¿¡æ¯ï¼Œä¸è¦è·¨è¶Šé¡µæ•°ï¼Œ è™½ç„¶å¯ä»¥å‚è€ƒï¼Œä½†ä¸è¦å°†ä¸åŒé¡µçš„ä¿¡æ¯åˆå¹¶åˆ°ä¸€èµ·ã€‚
        - **å®äº‹æ±‚æ˜¯**ï¼šå¦‚æœPPTä¸­æ²¡æœ‰æ˜æ˜¾çš„ç« èŠ‚åˆ†éš”é¡µï¼Œåˆ™ä¸è¦å¼ºè¡Œåˆ›å»ºç« èŠ‚ç»“æ„ï¼Œsectionsä¿æŒä¸ºç©ºã€‚
        - **ä¸è¦ä¿®æ­£äººä¸ºé”™è¯¯**ï¼šå¦‚æœç›®å½•æˆ–ç« èŠ‚é¡µä¸­å­˜åœ¨äººä¸ºé”™è¯¯æ²¡æœ‰å¯¹åº”ä¸Šï¼Œä¹Ÿä¸è¦ä¿®æ­£é”™è¯¯ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬åç»­éœ€è¦åˆ†æçš„ã€‚
        - **æ–‡æœ¬å—ä½ç½®**ï¼š æ–‡æœ¬å—ä½ç½®æ˜¯æ–‡æœ¬å—åœ¨é¡µé¢ä¸­çš„ä½ç½®ï¼Œ å•ä½ä¸ºç™¾åˆ†æ¯”ï¼Œ ç›¸å¯¹å·¦ä¸Šè§’ï¼Œè¿™åœ¨åˆ†æç›®å½•ã€ç« èŠ‚é¡µæ—¶éå¸¸é‡è¦ã€‚
        - **æ–‡æœ¬å—æ•°é‡**ï¼š æ–‡æœ¬å—æ•°é‡æ˜¯è¯¥é¡µçš„æ–‡æœ¬å—æ•°é‡ï¼Œ ä¸€èˆ¬ä¸º1ï¼Œè¯¥é¡µæœ‰å¤šä¸ªæ–‡æœ¬å—é€šå¸¸ä¸æ˜¯ç« èŠ‚é¡µï¼Œ ä½†æœ‰å¯èƒ½å·¦ä¸Šè§’ä¹Ÿä¼šæœ‰ä¸€ä¸ªæ–‡æœ¬å—ï¼Œä½†å…¶æ–‡æœ¬å†…å®¹è¾ƒå°‘æˆ–ä¸ºç©ºã€‚
        - **æ®µè½å±æ€§**ï¼š æ¯ä¸ªæ–‡æœ¬å—åŒ…å«æŒ‰ run åˆå¹¶åçš„â€œæ®µè½å±æ€§â€æ•°ç»„ï¼ˆå­—ä½“ã€å­—å·ã€é¢œè‰²ã€æ ·å¼ã€å­—ç¬¦å†…å®¹ï¼‰ã€‚

        è¾“å‡ºæ ¼å¼ï¼ˆåªè¾“å‡ºJSONå¯¹è±¡ï¼Œä¸è¦è§£é‡Šï¼‰ï¼š
        {{
        "topic": {{"text": str, "page": int}},
        "contents": [{{"text": str, "page": int}}],
        "sections": [{{"text": str, "page": int}}],
        "titles": [{{"text": str, "page": int}}]
        }}

        ä»¥ä¸‹æ˜¯PPTçš„åŸå§‹æ•°æ®ï¼Œè¯·ç›´æ¥åˆ†æï¼š
        {json.dumps(slides_data, ensure_ascii=False, indent=2)}"""


    print(f"ğŸ” å¼€å§‹LLMè°ƒç”¨: provider={llm.provider}, model={llm.model}, max_tokens={llm.max_tokens}")
    raw = llm.complete(prompt)

    data = json.loads(raw)
    return data




def analyze_from_parsing_result(parsing_data: Dict[str, Any], llm: Optional[LLMClient] = None) -> Dict[str, Any]:
    """ä¸€ç«™å¼ï¼šåŠ è½½parserç»“æœ â†’ è°ƒä¸€æ¬¡LLMè¿”å›é¢˜ç›®/ç›®å½•/ç« èŠ‚/æ¯é¡µæ ‡é¢˜ã€‚
    è¿”å›ï¼š{"topic": str, "contents": [...], "sections": [...], "titles": [...], "structure": str, "page_types": [...], "page_titles": [...]}ã€‚
    å®Œå…¨ä¾èµ–å¤§æ¨¡å‹åˆ†æï¼Œæ— è§„åˆ™æ³•å›é€€ã€‚"""
    # æå–å¹»ç¯ç‰‡æ•°æ®
    slides_data = parsing_data.get("contents", [])
    if not slides_data:
        return parsing_data
    
    llm_all = infer_all_structures(slides_data, llm)
    
    # ç”ŸæˆPPTç»“æ„æ±‡æ€»å­—ç¬¦ä¸²
    structure_lines = []
    
    # 1. ä¸»é¢˜
    topic_obj = llm_all.get('topic', '')
    topic_title = ""
    topic_page = 1
    if isinstance(topic_obj, dict):
        topic_title = topic_obj.get('text', '') or ""
        tp = topic_obj.get('page')
        if isinstance(tp, int) and tp > 0:
            topic_page = tp
    elif isinstance(topic_obj, str):
        topic_title = topic_obj
    structure_lines.append(f"ä¸»é¢˜ï¼š{topic_title or 'æ— '} ï¼ˆé¡µç ï¼š[{topic_page}]ï¼‰" if topic_title else "ä¸»é¢˜ï¼šæ— ")
    
    # 2. ç›®å½•é¡µ
    contents = llm_all.get('contents', [])
    if contents:
        structure_lines.append("ç›®å½•ï¼š")
        for item in contents:
            if isinstance(item, dict):
                title = item.get('text', '')
                page = item.get('page', None)
                line = f"      {title}" + (f" ï¼ˆé¡µç ï¼š[{page}]ï¼‰" if isinstance(page, int) else "")
                structure_lines.append(line)
            else:
                structure_lines.append(f"      {item}")
    else:
        structure_lines.append("ç›®å½•ï¼šæ— ")
    
    # 3. æŒ‰é¡µç é¡ºåºæ˜¾ç¤ºç« èŠ‚å’Œæ ‡é¢˜ï¼ˆå®äº‹æ±‚æ˜¯ï¼Œè¿˜åŸçœŸå®å†…å®¹ï¼‰
    sections = llm_all.get('sections', [])
    titles = llm_all.get('titles', [])
    # è§„èŒƒåŒ–ï¼šæ„å»º pageâ†’section_title / pageâ†’title çš„æ˜ å°„
    section_pages: Dict[int, Dict[str, Any]] = {}
    for sec in sections:
        if isinstance(sec, dict):
            # å…¼å®¹ {title,page} æˆ– {title,pages:[...]}
            pg = sec.get('page')
            if isinstance(pg, int):
                section_pages[pg] = sec
            else:
                pages = sec.get('pages', [])
                if isinstance(pages, list) and pages:
                    p0 = pages[0]
                    if isinstance(p0, int):
                        section_pages[p0] = sec

    titles_map: Dict[int, str] = {}
    if isinstance(titles, list):
        if titles and isinstance(titles[0], dict):
            for t in titles:
                if isinstance(t, dict):
                    pg = t.get('page')
                    title = t.get('text', '')
                    if isinstance(pg, int):
                        titles_map[pg] = title
        else:
            # æ—§æ ¼å¼ï¼šæŒ‰ç´¢å¼•å¯¹åº”é¡µç 
            for i, title in enumerate(titles):
                if isinstance(title, str):
                    titles_map[i + 1] = title
    
    # åˆå§‹åŒ–é¡µç±»å‹å’Œé¡µæ ‡é¢˜æ•°ç»„
    page_types = []
    page_titles = []
    
    total_pages = parsing_data.get('é¡µæ•°') or len(parsing_data.get('contents', [])) or max([0] + list(titles_map.keys()) + list(section_pages.keys()))

    if total_pages == 0:
        structure_lines.append("æ ‡é¢˜ï¼šæ— ")
    else:
        for page_num in range(1, total_pages + 1):
            if page_num == topic_page:
                # è·³è¿‡ä¸»é¢˜è¡Œé‡å¤æ‰“å°
                continue
            if any(isinstance(c, dict) and c.get('page') == page_num for c in contents):
                # ç›®å½•é¡µ
                continue
            if page_num in section_pages:
                sec = section_pages[page_num]
                stitle = sec.get('text', '')
                structure_lines.append(f"ç« èŠ‚ï¼š{stitle} ï¼ˆé¡µç ï¼š[{page_num}]ï¼‰")
            else:
                t = titles_map.get(page_num, '')
                if t:
                    structure_lines.append(f"æ ‡é¢˜ï¼š{t} ï¼ˆé¡µç ï¼š[{page_num}]ï¼‰")
    
    # ç”Ÿæˆstructureå­—ç¬¦ä¸²
    structure = "\n".join(structure_lines)
    print(f"ğŸ” ç»“æ„åˆ†æç»“æœ:\n {structure}")
    
    # ç”Ÿæˆé¡µç±»å‹å’Œé¡µæ ‡é¢˜æ•°ç»„
    for page_num in range(1, (total_pages or 0) + 1):
        # é¡µç±»å‹
        if page_num == topic_page:
            page_type = "ä¸»é¢˜é¡µ"
        elif any(isinstance(c, dict) and c.get('page') == page_num for c in contents):
            page_type = "ç›®å½•é¡µ"
        elif page_num in section_pages:
            page_type = "ç« èŠ‚é¡µ"
        else:
            page_type = "å†…å®¹é¡µ"
        page_types.append(page_type)

        # é¡µæ ‡é¢˜
        if page_num == topic_page:
            page_titles.append(topic_title)
        elif page_num in section_pages:
            page_titles.append(section_pages[page_num].get('text', ''))
        else:
            page_titles.append(titles_map.get(page_num, ''))
    
    parsing_data["structure"] = structure
    
    for i, page in enumerate(parsing_data.get("contents", [])):
        if i < len(page_types):
            page["é¡µç±»å‹"] = page_types[i]
        if i < len(page_titles):
            page["é¡µæ ‡é¢˜"] = page_titles[i]
    
    return parsing_data


if __name__ == "__main__":
    from pptlint.config import load_config
    cfg = load_config("configs/config.yaml")
    print(cfg.llm_provider)
    print(cfg.llm_api_key)
    print(cfg.llm_endpoint)
    print(cfg.llm_model)
    print(cfg.llm_temperature)
    print(cfg.llm_max_tokens)
    llm = LLMClient(
        provider=getattr(cfg, 'llm_provider', 'deepseek'),
        api_key=getattr(cfg, 'llm_api_key', None),
        endpoint=getattr(cfg, 'llm_endpoint', None),
        model=getattr(cfg, 'llm_model', 'deepseek-chat'),
        temperature=getattr(cfg, 'llm_temperature', 0.2),
        max_tokens=getattr(cfg, 'llm_max_tokens', 9999)
    )
    # é™é»˜è¿è¡Œï¼Œåªæ›´æ–° parsing_result.json
    parsing_data = load_parsing_result("parsing_result.json")

    parsing_data = analyze_from_parsing_result(parsing_data, llm)
    
    print(parsing_data['structure'])
    
    # å†™å›æ–‡ä»¶
    with open("parsing_result.json", "w", encoding="utf-8") as f:
        json.dump(parsing_data, f, ensure_ascii=False, indent=2)
