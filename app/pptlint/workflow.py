"""
å·¥ä½œæµç¼–æ’å™¨ï¼šæ ¹æ®ã€Šå®¡æŸ¥éœ€æ±‚æ–‡æ¡£ã€‹ä¸é…ç½®ï¼ŒåŠ¨æ€ä¸²è”ç»„ä»¶ã€‚
æ”¯æŒè§„åˆ™+LLMæ··åˆå®¡æŸ¥æ¨¡å¼ï¼ŒLLMä¸å¯ç”¨æ—¶è‡ªåŠ¨é™çº§ä¸ºçº¯è§„åˆ™ã€‚

è¾“å…¥ï¼šparsing_result.json æ ¼å¼çš„æ•°æ®
è¾“å‡ºï¼šå®¡æŸ¥ç»“æœã€æŠ¥å‘Šã€æ ‡è®°PPTç­‰
"""
from typing import List, Optional

from .config import ToolConfig
from .model import Issue
from .llm import LLMClient
from .tools.workflow_tools import (
    load_parsing_result,
    generate_report,
    generate_annotated_ppt,
    get_workflow_statistics,
    # æ–°å¢ï¼šPPTç¼–è¾‘åŠŸèƒ½
    create_ppt_context,
    run_llm_edit_analysis,
    apply_edits_to_ppt,
    save_modified_ppt,
    # æ–°å¢ï¼šè§„åˆ™æ£€æŸ¥
    convert_parsing_result_to_document_model,
    run_basic_rules
)
from .tools.llm_review import create_llm_reviewer
from .tools.structure_parsing import analyze_from_parsing_result

class WorkflowResult:
    def __init__(self):
        self.issues: List[Issue] = []
        self.report_md: Optional[str] = None
        self.rule_issues_count: int = 0
        self.llm_issues_count: int = 0


def run_review_workflow(parsing_result_path: str, cfg: ToolConfig, output_ppt: Optional[str], llm: Optional[LLMClient], original_pptx_path: Optional[str] = None) -> WorkflowResult:
    res = WorkflowResult()
    
    # æ­¥éª¤1ï¼šåŠ è½½ parsing_result.json
    print("ğŸ“– åŠ è½½è§£æç»“æœ...")
    parsing_data = load_parsing_result(parsing_result_path)
    if not parsing_data or parsing_data.get("é¡µæ•°", 0) == 0:
        print("âŒ åŠ è½½è§£æç»“æœå¤±è´¥æˆ–æ•°æ®ä¸ºç©º")
        return res
    
    # æ­¥éª¤2ï¼šåˆ†æPPTç»“æ„
    print("ğŸ” åˆ†æPPTç»“æ„...")
    try:
        parsing_data = analyze_from_parsing_result(parsing_data)
        print("âœ… PPTç»“æ„åˆ†æå®Œæˆ")
        
        # å°†ç»“æ„åˆ†æç»“æœé‡æ–°å†™å…¥parsing_result.json
        import json
        with open(parsing_result_path, "w", encoding="utf-8") as f:
            json.dump(parsing_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ç»“æ„åˆ†æç»“æœå·²æ›´æ–°åˆ°: {parsing_result_path}")
        
    except Exception as e:
        print(f"âš ï¸ PPTç»“æ„åˆ†æå¤±è´¥ï¼š{e}")
        # å³ä½¿ç»“æ„åˆ†æå¤±è´¥ï¼Œä¹Ÿç»§ç»­åç»­æµç¨‹
    
    # æ­¥éª¤3ï¼šè§„åˆ™æ£€æŸ¥
    print("ğŸ“‹ è¿è¡Œè§„åˆ™æ£€æŸ¥...")
    rule_issues = []
    try:
        doc_model = convert_parsing_result_to_document_model(parsing_data, parsing_result_path)
        rule_issues = run_basic_rules(doc_model, cfg)
        print(f"âœ… è§„åˆ™æ£€æŸ¥å®Œæˆï¼Œå‘ç° {len(rule_issues)} ä¸ªé—®é¢˜")
    except Exception as e:
        print(f"âš ï¸ è§„åˆ™æ£€æŸ¥å¤±è´¥ï¼š{e}")
    
    # æ­¥éª¤4ï¼šLLMå®¡æŸ¥ï¼ˆæŠ½å–ä¸ºå…¬å…±å‡½æ•°ï¼‰
    print("ğŸ¤– è¿è¡ŒLLMå®¡æŸ¥...")
    llm_issues = _perform_llm_review(parsing_data, cfg, llm)
    
    # åˆå¹¶æ‰€æœ‰é—®é¢˜
    all_issues = rule_issues + llm_issues
    res.issues = all_issues
    res.rule_issues_count = len(rule_issues)
    res.llm_issues_count = len(llm_issues)
    
    # æ­¥éª¤5ï¼šç”ŸæˆæŠ¥å‘Š
    print("ğŸ“Š ç”Ÿæˆå®¡æŸ¥æŠ¥å‘Š...")
    res.report_md = generate_report(all_issues, rule_issues, llm_issues)
    
    # æ­¥éª¤6ï¼šè¾“å‡ºæ ‡è®°PPTï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if output_ppt:
        if not original_pptx_path:
            print("âš ï¸ æ— æ³•ç”Ÿæˆæ ‡è®°PPTï¼šéœ€è¦æä¾›åŸå§‹PPTXæ–‡ä»¶è·¯å¾„")
        else:
            print("ğŸ·ï¸ ç”Ÿæˆæ ‡è®°PPT...")
            success = generate_annotated_ppt(original_pptx_path, all_issues, output_ppt)
            if success:
                print(f"âœ… æ ‡è®°PPTå·²ç”Ÿæˆ: {output_ppt}")
            else:
                print("âŒ ç”Ÿæˆæ ‡è®°PPTå¤±è´¥")
    
    # æ­¥éª¤7ï¼šè¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ¯ å®¡æŸ¥å®Œæˆï¼")
    print(f"   - è§„åˆ™æ£€æŸ¥ï¼š{res.rule_issues_count} ä¸ªé—®é¢˜")
    print(f"   - LLMå®¡æŸ¥ï¼š{res.llm_issues_count} ä¸ªé—®é¢˜")
    print(f"   - æ€»è®¡ï¼š{len(all_issues)} ä¸ªé—®é¢˜")
    
    return res


def _perform_llm_review(parsing_data, cfg: ToolConfig, llm: Optional[LLMClient]) -> List[Issue]:
    """å…¬å…±ï¼šåŸºäº parsing_result.json è°ƒç”¨LLMè¿›è¡Œå¤šç»´åº¦å®¡æŸ¥å¹¶è¿”å›é—®é¢˜åˆ—è¡¨ã€‚"""
    issues: List[Issue] = []
    
    # æ£€æŸ¥é…ç½®æ˜¯å¦å¯ç”¨LLM
    if not cfg.llm_enabled:
        print("ğŸ¤– LLMå®¡æŸ¥å·²ç¦ç”¨ï¼Œè·³è¿‡LLMå®¡æŸ¥æ­¥éª¤")
        return issues
    
    # å¦‚æœLLMå®¢æˆ·ç«¯æœªæä¾›ï¼Œè‡ªåŠ¨åˆ›å»ºä¸€ä¸ª
    if not llm:
        print("ğŸ¤– è‡ªåŠ¨åˆ›å»ºLLMå®¢æˆ·ç«¯...")
        from .llm import LLMClient
        llm = LLMClient()
    
    try:
        print("ğŸ¤– åˆ›å»ºLLMå®¡æŸ¥å™¨...")
        reviewer = create_llm_reviewer(llm, cfg)
        
        issues = []
        
        # æ ¹æ®é…ç½®å¼€å…³å†³å®šæ˜¯å¦æ‰§è¡Œå„é¡¹å®¡æŸ¥
        if cfg.review_format:
            print("ğŸ¤– å¼€å§‹æ ¼å¼æ ‡å‡†å®¡æŸ¥...")
            fmt = reviewer.review_format_standards(parsing_data)
            if fmt:
                issues.extend(fmt)
        else:
            print("ğŸ¤– æ ¼å¼æ ‡å‡†å®¡æŸ¥å·²ç¦ç”¨ï¼Œè·³è¿‡...")
        
        if cfg.review_logic:
            print("ğŸ¤– å¼€å§‹å†…å®¹é€»è¾‘å®¡æŸ¥...")
            logic = reviewer.review_content_logic(parsing_data)
            if logic:
                issues.extend(logic)
        else:
            print("ğŸ¤– å†…å®¹é€»è¾‘å®¡æŸ¥å·²ç¦ç”¨ï¼Œè·³è¿‡...")
        
        if cfg.review_acronyms:
            print("ğŸ¤– å¼€å§‹ç¼©ç•¥è¯­å®¡æŸ¥...")
            acr = reviewer.review_acronyms(parsing_data)
            if acr:
                issues.extend(acr)
        else:
            print("ğŸ¤– ç¼©ç•¥è¯­å®¡æŸ¥å·²ç¦ç”¨ï¼Œè·³è¿‡...")
        
        if cfg.review_fluency:
            print("ğŸ¤– å¼€å§‹æ ‡é¢˜ç»“æ„å®¡æŸ¥...")
            title = reviewer.review_title_structure(parsing_data)
            if title:
                issues.extend(title)
        else:
            print("ğŸ¤– æ ‡é¢˜ç»“æ„å®¡æŸ¥å·²ç¦ç”¨ï¼Œè·³è¿‡...")
        
    except Exception as e:
        print(f"âš ï¸ LLMå®¡æŸ¥å¤±è´¥ï¼š{e}")
    return issues

def run_edit_workflow(
    parsing_result_path: str, 
    original_pptx_path: str, 
    cfg: ToolConfig, 
    output_ppt: str, 
    llm: Optional[LLMClient] = None,
    edit_requirements: str = "è¯·åˆ†æPPTå†…å®¹ï¼Œæä¾›æ”¹è¿›å»ºè®®"
) -> WorkflowResult:
    """ç¼–è¾‘æ¨¡å¼ï¼šä½¿ç”¨LLMåˆ†æå¹¶è‡ªåŠ¨ä¿®æ”¹PPT"""
    res = WorkflowResult()
    
    print("âœï¸ å¯åŠ¨PPTç¼–è¾‘æ¨¡å¼...")
    
    # æ­¥éª¤1ï¼šåŠ è½½ parsing_result.json
    print("ğŸ“– åŠ è½½è§£æç»“æœ...")
    parsing_data = load_parsing_result(parsing_result_path)
    if not parsing_data or parsing_data.get("é¡µæ•°", 0) == 0:
        print("âŒ åŠ è½½è§£æç»“æœå¤±è´¥æˆ–æ•°æ®ä¸ºç©º")
        return res
    
    # æ­¥éª¤2ï¼šåˆ›å»ºPPTç¼–è¾‘ä¸Šä¸‹æ–‡
    print("ğŸ”„ åˆ›å»ºPPTç¼–è¾‘ä¸Šä¸‹æ–‡...")
    ppt_context = create_ppt_context(parsing_data, original_pptx_path)
    if not ppt_context:
        print("âŒ åˆ›å»ºPPTç¼–è¾‘ä¸Šä¸‹æ–‡å¤±è´¥")
        return res
    
    # æ­¥éª¤3ï¼šä¾èµ–å®¡æŸ¥ç»“æœï¼ˆä¸å®¡æŸ¥æ¨¡å¼å…±ç”¨çš„LLMå®¡æŸ¥é€»è¾‘ï¼‰
    print("ğŸ¤– è¿è¡Œå®¡æŸ¥ä»¥æ”¯æŒç¼–è¾‘...")
    review_issues = _perform_llm_review(parsing_data, cfg, llm)
    res.issues = review_issues
    
    # æ­¥éª¤4ï¼šä½¿ç”¨LLMåˆ†æå¹¶ç”Ÿæˆç¼–è¾‘å»ºè®®
    print("ğŸ¤– ä½¿ç”¨LLMåˆ†æPPTå†…å®¹...")
    # å¦‚æœLLMå®¢æˆ·ç«¯æœªæä¾›ï¼Œè‡ªåŠ¨åˆ›å»ºä¸€ä¸ª
    if not llm:
        print("ğŸ¤– è‡ªåŠ¨åˆ›å»ºLLMå®¢æˆ·ç«¯...")
        from .llm import LLMClient
        llm = LLMClient()
    edit_suggestions = run_llm_edit_analysis(parsing_data, llm, edit_requirements)
    
    if edit_suggestions:
        print(f"âœ… LLMç”Ÿæˆ {len(edit_suggestions)} ä¸ªç¼–è¾‘å»ºè®®")
        
        # æ­¥éª¤5ï¼šåº”ç”¨ç¼–è¾‘å»ºè®®åˆ°PPT
        print("ğŸ”§ åº”ç”¨ç¼–è¾‘å»ºè®®...")
        edit_result = apply_edits_to_ppt(ppt_context, edit_suggestions)
        
        if edit_result.success:
            # æ­¥éª¤6ï¼šä¿å­˜ä¿®æ”¹åçš„PPT
            print("ğŸ’¾ ä¿å­˜ä¿®æ”¹åçš„PPT...")
            if save_modified_ppt(ppt_context, output_ppt):
                print(f"âœ… ç¼–è¾‘å®Œæˆï¼ä¿®æ”¹åçš„PPTå·²ä¿å­˜åˆ°: {output_ppt}")
                
                # ç”Ÿæˆç¼–è¾‘æŠ¥å‘Š
                res.report_md = generate_edit_report(edit_result, edit_suggestions)
                res.rule_issues_count = len(edit_result.failed_suggestions)
                res.llm_issues_count = len(edit_result.applied_suggestions)
                
                # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
                print(f"\nğŸ¯ ç¼–è¾‘å®Œæˆï¼")
                print(f"   - æˆåŠŸåº”ç”¨ï¼š{len(edit_result.applied_suggestions)} ä¸ªå»ºè®®")
                print(f"   - å¤±è´¥å»ºè®®ï¼š{len(edit_result.failed_suggestions)} ä¸ª")
                print(f"   - ä¿®æ”¹é¡µé¢ï¼š{edit_result.modified_slides}")
                
                if edit_result.error_messages:
                    print(f"   - é”™è¯¯ä¿¡æ¯ï¼š{edit_result.error_messages}")
            else:
                print("âŒ ä¿å­˜ä¿®æ”¹åçš„PPTå¤±è´¥")
        else:
            print("âŒ åº”ç”¨ç¼–è¾‘å»ºè®®å¤±è´¥")
    else:
        print("â„¹ï¸ LLMæœªç”Ÿæˆç¼–è¾‘å»ºè®®")
    
    return res


def generate_edit_report(edit_result, edit_suggestions: List) -> str:
    """ç”Ÿæˆç¼–è¾‘æŠ¥å‘Š"""
    report = "# PPTç¼–è¾‘æŠ¥å‘Š\n\n"
    
    if edit_result.success:
        report += f"## âœ… ç¼–è¾‘æˆåŠŸ\n\n"
        report += f"- æˆåŠŸåº”ç”¨ï¼š{len(edit_result.applied_suggestions)} ä¸ªå»ºè®®\n"
        report += f"- ä¿®æ”¹é¡µé¢ï¼š{edit_result.modified_slides}\n"
        report += f"- è¾“å‡ºæ–‡ä»¶ï¼š{edit_result.output_path}\n\n"
        
        if edit_result.applied_suggestions:
            report += "## ğŸ“ å·²åº”ç”¨çš„ç¼–è¾‘\n\n"
            for suggestion in edit_result.applied_suggestions:
                report += f"### é¡µé¢ {suggestion.page_number} - å½¢çŠ¶ {suggestion.shape_index}\n"
                report += f"- ç±»å‹ï¼š{suggestion.type}\n"
                report += f"- å½“å‰å€¼ï¼š{suggestion.current_value}\n"
                report += f"- æ–°å€¼ï¼š{suggestion.new_value}\n"
                report += f"- åŸå› ï¼š{suggestion.reason}\n"
                report += f"- ä¼˜å…ˆçº§ï¼š{suggestion.priority}\n\n"
    else:
        report += "## âŒ ç¼–è¾‘å¤±è´¥\n\n"
    
    if edit_result.failed_suggestions:
        report += "## âš ï¸ å¤±è´¥çš„ç¼–è¾‘\n\n"
        for suggestion in edit_result.failed_suggestions:
            report += f"### é¡µé¢ {suggestion.page_number} - å½¢çŠ¶ {suggestion.shape_index}\n"
            report += f"- ç±»å‹ï¼š{suggestion.type}\n"
            report += f"- åŸå› ï¼š{suggestion.reason}\n\n"
    
    if edit_result.error_messages:
        report += "## ğŸš¨ é”™è¯¯ä¿¡æ¯\n\n"
        for error in edit_result.error_messages:
            report += f"- {error}\n\n"
    
    return report


