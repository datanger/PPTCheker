#!/usr/bin/env python3
"""
è°ƒè¯•è„šæœ¬ï¼šæŸ¥çœ‹æ¯ä¸ªé¡µé¢çš„è¯¦ç»†åˆ†æç»“æœ
åˆ†æä¸ºä»€ä¹ˆæŸäº›é¡µé¢æ²¡æœ‰è¢«æ­£ç¡®è¯†åˆ«
"""

import sys
import os
import re
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'app'))

from pptlint.parser import parse_pptx, _analyze_slide_content, _is_title_page, _is_toc_page, _is_chapter_page

def debug_analysis():
    """è°ƒè¯•åˆ†æè¿‡ç¨‹"""
    print("ğŸ” è°ƒè¯•é¡µé¢åˆ†æè¿‡ç¨‹...")
    
    pptx_path = "example1.pptx"
    if not os.path.exists(pptx_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {pptx_path}")
        return
    
    try:
        doc = parse_pptx(pptx_path)
        print(f"âœ… æˆåŠŸè§£æPPTæ–‡ä»¶ï¼Œå…± {len(doc.slides)} é¡µ")
        
        # ç¬¬ä¸€éæ‰«æï¼šæ”¶é›†ç›®å½•å†…å®¹
        toc_content = []
        for slide in doc.slides:
            for shape in slide.shapes:
                if shape.text_runs:
                    for text_run in shape.text_runs:
                        text = text_run.text.strip()
                        if text and re.match(r'^\d+[\.\s|ï½œ]', text):
                            toc_content.append(text)
        
        print(f"\nğŸ“‹ æ”¶é›†åˆ°çš„ç›®å½•å†…å®¹: {toc_content}")
        
        # åˆ†ææ¯ä¸ªé¡µé¢
        for i, slide in enumerate(doc.slides):
            print(f"\n{'='*50}")
            print(f"ğŸ“„ é¡µé¢ {i}: {slide.slide_title}")
            print(f"   å®é™…ç±»å‹: {slide.slide_type}")
            
            # åˆ†æé¡µé¢å†…å®¹ç‰¹å¾
            analysis = _analyze_slide_content(slide.shapes)
            print(f"\nğŸ” å†…å®¹åˆ†æ:")
            print(f"   æ€»æ–‡æœ¬é•¿åº¦: {analysis['total_text_length']}")
            print(f"   æ–‡æœ¬å—æ•°é‡: {analysis['text_blocks']}")
            print(f"   å­—ä½“å¤§å°: {analysis['font_sizes']}")
            print(f"   æœ‰ç¼–å·é¡¹ç›®: {analysis['has_numbered_items']}")
            print(f"   ç¼–å·æ¨¡å¼: {analysis['numbered_patterns']}")
            print(f"   å·¦ä¸Šè§’æ–‡æœ¬: {[t['text'] for t in analysis['top_left_texts']]}")
            print(f"   å¤§å­—ä½“æ–‡æœ¬: {[t['text'] for t in analysis['large_font_texts']]}")
            
            # æµ‹è¯•å„ç§åˆ¤æ–­å‡½æ•°
            print(f"\nğŸ§ª åˆ¤æ–­ç»“æœ:")
            is_title = _is_title_page(i, slide.shapes, analysis)
            is_toc = _is_toc_page(slide.shapes, analysis)
            is_chapter = _is_chapter_page(slide.shapes, analysis, toc_content)
            
            print(f"   æ ‡é¢˜é¡µåˆ¤æ–­: {is_title}")
            print(f"   ç›®å½•é¡µåˆ¤æ–­: {is_toc}")
            print(f"   ç« èŠ‚é¡µåˆ¤æ–­: {is_chapter}")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªæ–‡æœ¬å—
            print(f"\nğŸ“ å‰3ä¸ªæ–‡æœ¬å—:")
            text_count = 0
            for shape in slide.shapes:
                for text_run in shape.text_runs:
                    if text_count < 3 and text_run.text.strip():
                        print(f"     {text_run.text.strip()} (å­—ä½“: {text_run.font_size_pt}pt)")
                        text_count += 1
                if text_count >= 3:
                    break
            
    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_analysis()
